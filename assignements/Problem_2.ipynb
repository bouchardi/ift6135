{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Problem_2v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/isabellebouchard/ift6135/blob/master/Problem_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VH4lIYcO1K6Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Problem 2\n",
        "\n",
        "**Instructions**: For this part of the assignment we will train a convolutional network on MNIST\n",
        "for 10 epochs using your favorite deep learning frameworks such as Pytorch of Tensor\n",
        "ow. Plot the\n",
        "train and valid errors at the end of each epoch for the model.\n",
        "1. Come up with a CNN architecture with more or less similar number of parameters as MLP\n",
        "trained in Problem 1 and describe it.\n",
        "2. Compare the performances of CNN vs MLP. Comment.\n",
        "\n",
        "You could take reference from the architecture mentioned here: \n",
        "https://github.com/MaximumEntropy/welcome_tutorials/tree/pytorch/pytorch \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "684DW9LYqBOQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Installation Requirements"
      ]
    },
    {
      "metadata": {
        "id": "bpLwFCA2qZ3Z",
        "colab_type": "code",
        "outputId": "4b752020-0778-4b58-dccb-6f754c758037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision matplotlib "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6XE-zREuubCO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use GPU \n",
        "\n",
        "First, select \"GPU\" in the Edit Menu -> Notebook Settings -> Hardware Accelerator -> GPU\n",
        "\n",
        "**torch.cuda**: *This package adds support for CUDA tensor types, that implement the same function as CPU tensors, but they utilize GPUs for computation.*\n",
        "\n",
        "**torch.cuda.is_available()**: *Returns a bool indicating if CUDA is currently available.*\n",
        "\n",
        "To go from a tensor type CPU to GPU, add .to(\"cuda:0\")"
      ]
    },
    {
      "metadata": {
        "id": "CazsaWTvwY4a",
        "colab_type": "code",
        "outputId": "40830f3c-faba-4640-d5c3-6cae26829148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "print(\"GPU Available: {}\".format(use_gpu))\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Available: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d-ds7UbtqNVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MNIST Data\n",
        "\n",
        "Get MNIST Data, split in train/validate/test and load in DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "CRsuMTDdEhJN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import sampler, DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "batch_size = 34\n",
        "\n",
        "# ChunkSampler class is from https://github.com/pytorch/vision/issues/168\n",
        "class ChunkSampler(sampler.Sampler):\n",
        "    \"\"\"Samples elements sequentially from some offset. \n",
        "    Arguments:\n",
        "        num_samples: # of desired datapoints\n",
        "        start: offset where we should start selecting from\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples, start = 0):\n",
        "        self.num_samples = num_samples\n",
        "        self.start = start\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.start + self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "train_set = MNIST(root='../data',train=True,transform=transforms.ToTensor(),download=True)\n",
        "test_set = MNIST(root='../data',train=False,transform=transforms.ToTensor(),download=True)\n",
        "\n",
        "train_set_size = len(train_set)\n",
        "NUM_TRAIN = int(0.8 * train_set_size) #cast to int to avoid TypeError: 'float' object cannot be interpreted as an integer\n",
        "NUM_VAL = train_set_size - NUM_TRAIN\n",
        "NUM_TEST = len(test_set)\n",
        "\n",
        "loader_train = DataLoader(train_set, batch_size=batch_size, sampler=ChunkSampler(NUM_TRAIN, 0),shuffle=False)\n",
        "loader_val = DataLoader(train_set, batch_size=batch_size, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN),shuffle=False)\n",
        "loader_test = DataLoader(test_set, batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19H5ZWImwdHt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CNN Model\n",
        "\n",
        "[torch.nn.Module](https://pytorch.org/docs/master/nn.html#torch.nn.Module): Base class for all NN modules. \n",
        "Must implement __init__ (defines the layers) and **forward** (returns the output)\n",
        "\n",
        "[torch.nn.Sequential(*args)](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential): Modules will be added to it in the order they are passed in the constructor\n",
        "\n",
        " [torch.nn.Conv2d](https://pytorch.org/docs/master/nn.html#torch.nn.Conv2d)(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
        " \n",
        "[ torch.nn.Sigmoid](https://pytorch.org/docs/master/nn.html#sigmoid)\n",
        "\n",
        "[torch.nn.MaxPool2d](https://pytorch.org/docs/master/nn.html#torch.nn.MaxPool2d)(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False): Applies a 2D max pooling over an input signal composed of several input planes.\n",
        "\n",
        " [torch.nn.Linear](https://pytorch.org/docs/master/nn.html#torch.nn.Linear)(in_features, out_features, bias=True)\n"
      ]
    },
    {
      "metadata": {
        "id": "BsuLybW3wyq2",
        "colab_type": "code",
        "outputId": "66614447-c0a0-4ef8-f173-dc740433bfcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import copy\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(1,32,kernel_size=5,padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2))\n",
        "    \n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(32,64,kernel_size=5,padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2))\n",
        "\n",
        "    self.conv3 = nn.Sequential(\n",
        "        nn.Conv2d(64,96,kernel_size=5,padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2))\n",
        "    \n",
        "    self.conv4 = nn.Sequential(\n",
        "        nn.Conv2d(96,246,kernel_size=3,padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2))\n",
        "    \n",
        "    self.conv5 = nn.Sequential(\n",
        "        nn.Conv2d(246,246,kernel_size=3,padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2))\n",
        "    \n",
        "    \n",
        "    self.fc = nn.Linear(2*2*246,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.conv4(out)\n",
        "    out = self.conv5(out)\n",
        "    flatten = out.view(out.size(0),-1)\n",
        "    fc = self.fc(flatten)\n",
        "    return fc\n",
        "\n",
        "model = CNN()\n",
        "# put model on GPU\n",
        "model = model.to(device)\n",
        "\n",
        "print(model)\n",
        "\n",
        "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "# Save the initial weights of model\n",
        "init_model_wts = copy.deepcopy(model.state_dict())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(64, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(96, 246, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(246, 246, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=984, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "# Parameters:  973322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "av0WomNHWIpa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train CNN\n",
        "\n",
        "#### Loss function\n",
        "\n",
        "criterion = [torch.nn.CrossEntropyLoss](https://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss)(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
        "\n",
        "#### Minimize loss function using stochastic gradient descent\n",
        "optimizer = [torch.optim.SGD](https://pytorch.org/docs/master/optim.html#torch.optim.SGD)(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n"
      ]
    },
    {
      "metadata": {
        "id": "qNbuxqGNWPGs",
        "colab_type": "code",
        "outputId": "84fc6a9e-7385-4fe1-a69d-69f6ca46ff84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1649
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-2\n",
        "num_epochs = 24\n",
        "patience = 0\n",
        "\n",
        "#loss function\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "\n",
        "#optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.load_state_dict(init_model_wts)\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_acc = 0.0\n",
        "\n",
        "train_errors = []\n",
        "eval_errors = []\n",
        "acc = []\n",
        "\n",
        "print(\"Training begins...\")\n",
        "since = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  \n",
        "  train_error = 0\n",
        "  train_num = 0\n",
        "  \n",
        "  # model in train mode\n",
        "  model.train()\n",
        "  \n",
        "  for digits, labels in loader_train:\n",
        "    \n",
        "    # digits and labels on GPU\n",
        "    digits = digits.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # zero gradient buffer\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # forward pass\n",
        "    outputs = model(digits)\n",
        "        \n",
        "    # loss function\n",
        "    loss = criterion(outputs,labels)\n",
        "        \n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # gradient descent step\n",
        "    optimizer.step()\n",
        "    \n",
        "    # add the loss\n",
        "    train_error += loss.item()\n",
        "    train_num += 1\n",
        "  \n",
        "  eval_error = 0\n",
        "  eval_num = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  # model in eval mode\n",
        "  model.eval()\n",
        "  \n",
        "  for digits, labels in loader_val:\n",
        "    \n",
        "    # digits and labels on GPU\n",
        "    digits = digits.to(device)\n",
        "    labels = labels.to(device)\n",
        "        \n",
        "    # forward pass\n",
        "    outputs = model(digits)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # loss function\n",
        "    loss = criterion(outputs,labels)\n",
        "        \n",
        "    # add the loss\n",
        "    eval_error += loss.item()\n",
        "    eval_num += 1\n",
        "    \n",
        "    # save the accuary\n",
        "    total += labels.size(0)\n",
        "    correct += torch.sum(predicted == labels.data)\n",
        "  \n",
        "  #calculate epoch accuracy\n",
        "  accuracy = (100 * correct)/total\n",
        "    \n",
        "  # deep copy the model of best epoch accuracy\n",
        "  if accuracy > best_acc:\n",
        "    best_acc = accuracy\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    patience = 0\n",
        "  else:\n",
        "    patience += 1\n",
        "  if patience == 3:\n",
        "    learning_rate /= 2\n",
        "  if patience > 4:\n",
        "    print('early stopping')\n",
        "    break\n",
        "    \n",
        "  # save the loss\n",
        "  train_errors.append(train_error / train_num)\n",
        "  eval_errors.append(eval_error / eval_num)\n",
        "  \n",
        "  acc.append(accuracy)\n",
        "  \n",
        "  #print stats after each epoch\n",
        "  print('\\nEpoch {}'.format(epoch + 1))\n",
        "  print('\\nPatience {}'.format(patience))\n",
        "  print('\\tTrain error: {:.4f}'.format(train_error/train_num))  \n",
        "  print('\\tEval error: {:.4f}'.format(eval_error/eval_num))\n",
        "  print('\\tAccuracy on Eval set: {:.2f}%'.format(accuracy))\n",
        "  \n",
        "time_elapsed = time.time() - since\n",
        "print('\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "print('Best Eval Acc: {:.2f}%'.format(best_acc))\n",
        "\n",
        "# load best model weights\n",
        "model.load_state_dict(best_model_wts)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training begins...\n",
            "\n",
            "Epoch 1\n",
            "\n",
            "Patience 0\n",
            "\tTrain error: 2.2885\n",
            "\tEval error: 2.2232\n",
            "\tAccuracy on Eval set: 28.00%\n",
            "\n",
            "Epoch 2\n",
            "\n",
            "Patience 0\n",
            "\tTrain error: 0.7881\n",
            "\tEval error: 0.2311\n",
            "\tAccuracy on Eval set: 93.00%\n",
            "\n",
            "Epoch 3\n",
            "\n",
            "Patience 0\n",
            "\tTrain error: 0.1796\n",
            "\tEval error: 0.1407\n",
            "\tAccuracy on Eval set: 95.00%\n",
            "\n",
            "Epoch 4\n",
            "\n",
            "Patience 0\n",
            "\tTrain error: 0.1131\n",
            "\tEval error: 0.1010\n",
            "\tAccuracy on Eval set: 96.00%\n",
            "\n",
            "Epoch 5\n",
            "\n",
            "Patience 0\n",
            "\tTrain error: 0.0860\n",
            "\tEval error: 0.0870\n",
            "\tAccuracy on Eval set: 97.00%\n",
            "\n",
            "Epoch 6\n",
            "\n",
            "Patience 1\n",
            "\tTrain error: 0.0703\n",
            "\tEval error: 0.0775\n",
            "\tAccuracy on Eval set: 97.00%\n",
            "\n",
            "Epoch 7\n",
            "\n",
            "Patience 2\n",
            "\tTrain error: 0.0595\n",
            "\tEval error: 0.0703\n",
            "\tAccuracy on Eval set: 97.00%\n",
            "\n",
            "Epoch 8\n",
            "\n",
            "Patience 3\n",
            "\tTrain error: 0.0514\n",
            "\tEval error: 0.0660\n",
            "\tAccuracy on Eval set: 97.00%\n",
            "\n",
            "Epoch 9\n",
            "\n",
            "Patience 0\n",
            "\tTrain error: 0.0450\n",
            "\tEval error: 0.0629\n",
            "\tAccuracy on Eval set: 98.00%\n",
            "\n",
            "Epoch 10\n",
            "\n",
            "Patience 1\n",
            "\tTrain error: 0.0397\n",
            "\tEval error: 0.0607\n",
            "\tAccuracy on Eval set: 98.00%\n",
            "\n",
            "Epoch 11\n",
            "\n",
            "Patience 2\n",
            "\tTrain error: 0.0352\n",
            "\tEval error: 0.0592\n",
            "\tAccuracy on Eval set: 98.00%\n",
            "\n",
            "Epoch 12\n",
            "\n",
            "Patience 3\n",
            "\tTrain error: 0.0314\n",
            "\tEval error: 0.0586\n",
            "\tAccuracy on Eval set: 98.00%\n",
            "\n",
            "Epoch 13\n",
            "\n",
            "Patience 4\n",
            "\tTrain error: 0.0281\n",
            "\tEval error: 0.0579\n",
            "\tAccuracy on Eval set: 98.00%\n",
            "early stopping\n",
            "\n",
            "Training complete in 6m 28s\n",
            "Best Eval Acc: 98.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jsv2qq5dxdXK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Train and Valid Errors"
      ]
    },
    {
      "metadata": {
        "id": "ppiHJuZTxl89",
        "colab_type": "code",
        "outputId": "a4c0365d-79b0-4318-8f21-d54beb2e04b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plot training and validation curve\n",
        "x = list(range(len(train_errors))) \n",
        "plt.plot(x, train_errors,'m',label='Train')\n",
        "plt.plot(x, eval_errors,'g', label='Validation')\n",
        "\n",
        "plt.xlabel('Number Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='best',shadow=True, fancybox=True)\n",
        "plt.title(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "20iwVyynyVgH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test CNN"
      ]
    },
    {
      "metadata": {
        "id": "NMzvWhFxyXhl",
        "colab_type": "code",
        "outputId": "bc5cafda-6de7-46a9-f8dc-8169c89a0156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# model in eval mode\n",
        "model.eval()\n",
        "\n",
        "correct = 0.0\n",
        "total = 0.0\n",
        "\n",
        "for digits, labels in loader_test:\n",
        "  \n",
        "  # digits and labels on GPU\n",
        "  digits = digits.to(device)\n",
        "  labels = labels.to(device)\n",
        "  \n",
        "  # forward pass\n",
        "  outputs = model(digits)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  \n",
        "  # save the accuary\n",
        "  total += labels.size(0)\n",
        "  correct += torch.sum(predicted == labels.data)\n",
        "print (correct)\n",
        "print (total)\n",
        "print('Accuracy on the test set: {:.4f}%'.format(100.0 * correct / total))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(9825, device='cuda:0')\n",
            "10000.0\n",
            "tensor(98, device='cuda:0')\n",
            "Accuracy on the test set: 98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TzYy6Fe31sCs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN vs. MLP \n",
        "\n",
        "## Number of parameters\n",
        "\n",
        "**CNN with 4 conv layers**\n",
        "\n",
        "conv1 = 32 filters size 5x5 + 32 biases = 32x5x5+32 = 832\n",
        "\n",
        "conv2 = 32x64 filters size 5x5 + 64 biases = 32x64x5x5 + 64 = 51,264\n",
        "\n",
        "conv3 = 64x96 filters size 5x5 + 96 biases = 64x96x5x5 + 128 = 153696\n",
        "\n",
        "conv4 = 96x246 filters size 3x3 + 246 biases = 96x246x3x3 + 246 = 212790\n",
        "\n",
        "conv5 = 246x246 filters size 3x3 + 246 biases = 246x246x3x3 + 246 = 544890\n",
        "\n",
        "fc = 1x(2x2x246) x 10 + 10 = 9850\n",
        "\n",
        "total CNN parameters = 832 + 51,264 + 153,696 +212790 + 544890 + 9850 = **973322**\n",
        "\n",
        "\n",
        "\n",
        "**MLP with 2 hidden layers**\n",
        "\n",
        "input to h1 = 784 x 512 + 512 = 401,408\n",
        "\n",
        "h1 to h2 = 512 x 1024 + 1024 = 524,288\n",
        "\n",
        "h2 to output = 1024 x 10  + 10 = 10,240\n",
        "\n",
        "total MLP parameters = 401,408 + 524,288 + 10,240 = **937482**\n",
        "\n",
        "## Discussion\n",
        "\n",
        "CNN's need significantly less parameters than MLP since they exhibit sparse connectivity and parameter sharing. \n",
        "\n",
        "**Sparse connectivity**: direct connections very sparse, but in the deeper layers, units are indirectly connected to all/most of the input image. \n",
        "\n",
        "**Parameter sharing**: each member of the kernel is used at every position of the input, meaning the same parameters are used at all input locations. Therefore you learn only one set of parameters. \n",
        "\n",
        "Since we are asked to build a CNN with similar number of parameters as the MLP trained in Problem 1, the CNN should outperform the MLP since it needs a significantly smaller number of weights to be able to match an MLP's performance. \n",
        "\n",
        "## Performance\n",
        "\n",
        "If m represents the size of the input image, and n the size of the output image, then MLP requires mxn parameters with O(mxn) runtime. In CNNs, you limit the number of connections of each output to k, this means you only need kxn parameters with O(kxn) runtime. \n"
      ]
    }
  ]
}